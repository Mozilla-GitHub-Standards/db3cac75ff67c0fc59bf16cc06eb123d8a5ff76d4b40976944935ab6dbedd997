%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 
%% Informal notes on k-randomization.
%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass[11pt,draft]{article}
%\documentclass[11pt,draft]{amsart}

%% Custom styling.
\usepackage{mozdp}
%% Controls enumeration labels
%\usepackage{enumerate}
%% Shrinks margins 
\usepackage{fullpage}
%% Shows equation label keys
%\usepackage[notref]{showkeys}

%% Some convenience aliases.
\newcommand{\Dsp}{\mathcal{D}}
\newcommand{\Ssp}{\mathcal{S}}
\newcommand{\xv}{\mathbf{x}}
\newcommand{\yv}{\mathbf{y}}
\newcommand{\sv}{\mathbf{s}}
\newcommand{\xvt}{\tilde{\xv}}
\newcommand{\yvt}{\tilde{\yv}}
\newcommand{\sm}{\sv^-}
\newcommand{\iv}{\mathbf{i}}
\newcommand{\one}{\boldsymbol{1}}

%% Title matter
\title{K-Randomization}
\author{Maxim Zhilyaev \and David Zeber}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\maketitle

\section{Differential Privacy}
\label{sec:dp}

The typical setting for differential privacy is as follows. 
We consider a \textbf{database} as a collection of records. 
Each record is an element of some space $\Dsp$, and a database $\xv$ is a vector of $n$ records: $\xv = (x_1,\dots,x_n) \in \Dsp^n$.

We wish to release information retrieved from the database by means of a \textbf{query}, a function $A$ mapping the database into another space: $\map{A}{\Dsp^n}{\Ssp}$. The result of applying a query to a database is termed a \textbf{transcript}.
The query usually applies some aggregation to the database records, and so the output space $\Ssp$ is generally of lower dimensionality than the original database.
If the query is randomized, \ie $A(\xv) = A(\xv; \xi)$ for a random element $\xi$, then the transcript will be a random element of $\Ssp$.

The notion of differential privacy for a database query is that the resulting transcript does not change substantially when a record in the database is modified,
\ie transcripts are not sensitive to particular individual records in the database.
Hence, releasing query transcripts publicly will not jeopardize privacy, since information regarding individual records cannot be gained by analyzing query transcripts.

%%% Differential privacy definition

Differential privacy for a randomized query $A$ is formulated by comparing the transcripts generated by applying $A$ to two very similar databases $\xv,\xv' \in \Dsp^n$.
We say the databases \textbf{differ in one row} if 
$\sum_{i=1}^n I(x_i \neq x'_i) = 1$.
\begin{defn}
A randomized query $A$ is $\epsilon$-\textbf{differentially private} if, 
for any two databases $\xv,\xv' \in \Dsp^n$ differing in one row,
\begin{equation}\label{eq:dpdef}
\P[A(\xv) \in S] \leq \exp(\epsilon) \cdot \P[A(\xv') \in S]
\end{equation}
for all $S \cont \Ssp$ (measurable).
\end{defn}
In other words, the transcripts from the two databases databases differing in one row are close in distribution.
An alternative notion of differing in one row that is sometimes used is that $\xv'$ includes an additional record that is not in $\xv$:
$\xv\in \Dsp^n$, $\xv' \in \Dsp^{n+1}$, and $x_i = x'_i$ for $i = 1,\dots,n$.

%%% Countable output space

%% TODO: countable vs. finite
%% TODO: Lemma for bounding ratio of sums

If $\Ssp$ is finite, which is common in cases where the transcript involves integer counts, then the distribution of the transcript $A(\xv)$ can be represented using its pmf $\P[A(\xv) = s]$ for $s \in \Ssp$.
In this case, the differential privacy condition can also be expressed in terms of the pmf.
\begin{prop} \label{prop:dpcnt}
If $\Ssp$ is finite, then $A$ is $\epsilon$-\textbf{differentially private} if and only if
\begin{equation} \label{eq:dpcnt}
\P[A(\xv) = s] \leq \exp(\epsilon) \cdot \P[A(\xv') = s]
\end{equation}
for all $s\in\Ssp$, where $\xv,\xv'$ differ in one row.
\end{prop}
\begin{pf}
\pfleftdir
Given $S \cont \Ssp$, we can write
$\P[A(\xv) \in S] = \sum_{s \in S} \P[A(\xv) = s]$.
If $\P[A(\xv') \in S] = 0$, then $\P[A(\xv') = s] = 0$ for each $s \in S$.
From \eqref{eq:dpcnt} we have that $\P[A(\xv) = s] = 0$ as well, and so $P[A(\xv) \in S] = 0$, verifying \eqref{eq:dpdef}.
Otherwise, if $\P[A(\xv') \in S] > 0$,
\[ \frac{\P[A(\xv) \in S]}{\P[A(\xv') \in S]}
= \frac{\sum_{s \in S} \P[A(\xv) = s]}{\sum_{s \in S} \P[A(\xv') = s]}
\leq \max_{s \in S} \frac{\P[A(\xv) = s]}{\P[A(\xv') = s]}
\leq \exp(\epsilon), \]
using Lemma \ref{lem:rsbound}.\\
\pfrightdir Take $S = \{s\}$ in \eqref{eq:dpdef}.
\end{pf}



\section{Bit vector reporting}

Our goal is to establish differential privacy properties for user data reported in the form of vectors of bits.
To protect user privacy, each user record is randomized prior to leaving the client and anonymized on reaching the server.
We now describe the randomization procedure, and place ourselves in the setting of Section \ref{sec:dp} by representing it as a query applied to a database.


\subsection{Bit randomization}

For our purposes, a \textbf{bit} is an integer $b \in \{0,1\}$, and a \textbf{bit vector} is a vector $x \in \{0,1\}^L$.
Bits and bit vectors are randomized in the following way.

\begin{defn}
The \textbf{bit randomization} procedure $R$ with \textbf{lie probability} $0 < q < 1/2$ flips a bit $b$ with probability $q$, and leaves it as-is with probability $p := 1-q$:
\[ R(b) =
\begin{cases}
b & \text{with prob }p \\
1-b & \text{with prob }q
\end{cases}.
\]
This can be expressed concisely as
\[ R(b) = R(b; \xi) = b \cdot \xi + (1-b) \cdot (1-\xi)
\quad\text{where } \xi\sim Ber(p). \]
We extend the procedure to \textbf{bit vector randomization} by applying the randomization independently to each bit in the vector.
Given a bit vector $x = (b_1,\dots,b_L)$, define
\[ R(x) = R(x;\xi) = \big(R(b_1;\xi_1), \dots, R(b_L;\xi_L)\big)
\quad\text{where } \xi = (\xi_1,\dots,\xi_L) \iid Ber(p). \]
\end{defn}

\begin{rmk}
Note that $R$ reports the original bit value with probability $p = 1-q > q$, and lies with probability $q$.
This is equivalent to the randomized response procedure where the value is reported as-is with probability $1-f$, and with probability $f$ the reported value is the outcome of the toss of a fair coin.
In our case, $q = f/2$.
\end{rmk}
\begin{rmk}
If $q = 1/2$, then $R(0)\eqdist R(1)$, and the reported value is ``completely'' randomly generated, \ie independently of the original value.
\end{rmk}

%%% Distribution of randomized bit vectors.

We now consider the distribution of the randomized bit vectors.
It can be expressed in terms of the Hamming distance between the original and randomized vectors:
\[ \delta(x,x') = \sum_{\ell = 1}^L I(x_\ell \neq x'_\ell)
= \sum_{\ell = 1}^L |x_\ell - x'_\ell|. \]
For a single bit, the randomization has lied when the outcome is different from the original value: 
\[ \P[R(b) = y] = p^{I(b = y)}\cdot q^{I(b \neq y)}
= (1-q)^{1 - \delta(b,y)}\cdot q^{\delta(b,y)}. \]
For a bit vector $x$, this becomes
\[ \P[R(x) = y] = p^{\sum I(x_\ell = y_\ell)}\cdot q^{\sum I(x_\ell \neq y_\ell)}
= (1-q)^{L-\delta(x,y)}\cdot q^{\delta(x,y)}.
\]
Note that this probability is maximized when $\delta(x,y) = 0$ (the randomized vector $y$ is identical to the original vector $x$), and minimized when $\delta(x,y) = L$.
In the latter case, we say that $y$ is the \textbf{opposite} of $x$.
In other words, the most likely outcome of randomizing a bit vector is obtaining an identical vector.

\subsection{Reporting for bit records}

We now place ourselves in the setting of Section \ref{sec:dp} for bit-vector user records, as required in the sequel.

Set $\Dsp = \{0,1\}^L$. We use the term \textbf{collection} (of records) interchangeably with ``database''.
We consider a randomized query $A$ that randomizes each record in the collection independently, and aggregates the results by reporting occurrence counts for every possible randomization outcome.
We adopt this aggregation step as a model for anonymization. After anonymization, any link to the original collection or ordering is lost, and the information contained in the results is embodied solely by the reported values.

In the following, we rely on the fact that $\Dsp$ is finite, and we assume a specific enumeration $\Dsp = (d_1,\dots,d_{2^L})$. The ordering is unimportant at this point, although it will be convenient to assume that $d_1 =  (1,\dots,1)$ and $d_{2^L} = (0,\dots,0)$.

\begin{defn}
The randomized query $\map{A}{\Dsp^n}{\Ssp_n = \{0,\dots,n\}^{2^L}}$ maps collections of bit vectors to occurrence counts as follows.
\begin{enumerate}
\renewcommand{\labelenumi}{(\alph{enumi})}
\item Extend the bit randomization $R$ to collections $\xv$ by applying it independently to each vector:
\[ R(\xv) = R(\xv;\boldsymbol{\xi})
= \big(R(x_1;\xi_1),\dots,R(x_n; \xi_n)\big)
\quad\text{where } \xi_i = (\xi_{i1},\dots,\xi_{iL}) \text{ and }
\xi_{i\ell} \iid Ber(p). \]
We call $R(\xv)$ the \textbf{synthetic} collection obtained from the \textbf{original} collection $\xv$.
\item Define the function $\Phi$ that counts occurrences of the elements of $\Dsp = (d_1,\dots,d_{2^L})$ in a collection $\yv$:
\[ \Phi(\yv) := \left(\sum_{i = 1}^n I(y_i = d_1),\dots,
\sum_{i = 1}^n I(y_i = d_{2^L}).
\right)
\]
Note that, if $\Phi(\yv) = (s_1,\dots,s_{2^L})$, then $s_1 + \cdots + s_{2^L} = n$.
\end{enumerate}
Finally,
\[ A  = \Phi \circ R. \]
\end{defn}

The distribution of $A(\xv)$ is given by
\begin{align}
\P[A(\xv) = \sv] &= \P[\Phi(R(\xv)) = s]
= \sum_{\yv:\Phi(\yv) = s} \P[R(\xv) = \yv] \nonumber\\
&= \sum_{\yv:\Phi(\yv) = s} \prod_{i=1}^n \P[R(x_i) = y_i]
\label{eq:Adist}\\
&= \sum_{\yv:\Phi(\yv) = s} \prod_{i=1}^n p^{L - \delta(x_i,y_i)}\cdot
q^{\delta(x_i,y_i)}
= \sum_{\yv:\Phi(\yv) = s} p^{nL - \delta(\xv,\yv)}\cdot
q^{\delta(\xv,\yv)}  \nonumber
\end{align}
Note that the support of $A$ is the support of a multinomial random variable with $n$ trials: \[\Ssp_n := \bigg\{s \in \Ssp : \sum_j s_j = n \bigg\}.\]


\section{The privacy ratio}

We will study the differential privacy of the query $A$ in terms of the \textbf{privacy ratio}
\[ \pi(\sv;\xv,\xv') := \frac{\P[A(\xv') = \sv]}{\P[A(\xv) = \sv]} \]
for two collections $\xv,\xv'\in\Dsp^n$ differing in one row and $\sv \in\Ssp_n$.
Note that $\pi$ is well-defined, since any outcome in $\Ssp_n$ occurs with non-zero probability starting from any collection $\xv$.

Differential privacy is typically concerned with bounding the privacy ratio over all original and synthetic collections.
In particular, by Proposition \ref{prop:dpcnt}, $A$ is $\epsilon$-differentially private if $\pi$ is bounded everywhere on $\Ssp$,
with
\[ \epsilon = \max_{\substack{\sv\in\Ssp\\ \xv,\xv' \in \Dsp^n}} \log\pi(\sv;\xv,\xv'). \]
We take this further by studying the behaviour of the privacy ratio and how it varies across the support of $A$ and across collections. This will allow us to understand in which situations it is at or near its bound.

Without loss of generality (in light of \eqref{eq:Adist}), assume that the element differing between $\xv$ and $\xv'$ is the first one, and denote $\xvt = (x_2,\dots,x_n)$.
In other words, $\xv = (x_1,\xvt)$ and $\xv' = (x'_1, \xvt)$.
We also write $\iv_j = (0,\dots,0,1,0,\dots,0)$, the vector with a 1 in the $j$-th position and the rest 0.
%For convenience, introduce the notation
%$\sm_j = (s_1,\dots,s_{j-1},s_j - 1,s_{j+1},\dots,s_{2^L})$.

Conditioning on the value of the modified record, we can write
\begin{equation} \label{eq:prcond}
\pi(\sv;\xvt,x_1,x_1') = \frac{\displaystyle\sum_{j=1}^{2^L}
\P[A(x'_1) = \iv_j] \P[A(\xvt) = \sv - \iv_j]}
{\displaystyle\sum_{j=1}^{2^L}
\P[A(x_1) = \iv_j] \P[A(\xvt) = \sv - \iv_j]}
= \frac{\displaystyle\sum_{j=1}^{2^L}
\P[R(x'_1) = d_j] \P[A(\xvt) = \sv - \iv_j]}
{\displaystyle\sum_{j=1}^{2^L}
\P[R(x_1) = d_j] \P[A(\xvt) = \sv - \iv_j]}.
\end{equation}

TODO: consequences of this: \\
- difference between numerator and denominator is basically a reweighting of the same terms in the sum \\
- max value of ratio -  $~ (p/q)^L$ but doesn't depend on population size $n$

\section{The case $L = 1$}

It is instructive to first consider the case where each record in the collection consists of a single bit, as the expressions simplify considerably.

When $L=1$, each original and synthetic record is either 1 or 0, and the transformation $R$ flips each record with probability $q$.
Partition the collection space $\Dsp^n$ according to the number of records that are 1:
\[ \Dsp^n = \bigcup_{m = 0}^n \Dsp_m^n
\quad\quad\text{where}\quad\quad
\Dsp_m^n := \bigg\{ \xv\in\Dsp^n \,:\, \sum_{i=1}^n I(x_i = 1) = m \bigg\}.
\]
For $\xv\in\Dsp_m^n$, we have
\[ A(\xv) = \Phi\circ R(\xv) = \big(A_n(m), n - A_n(m)\big), \]
where
\begin{align*}
A_n(m) &:= \sum_{i=1}^n I(R(x_i) = 1)
= \sum_{i:\, x_i = 1} I(R(1) = 1) + \sum_{i:\, x_i = 0} I(R(0) = 1) \\
&\sim Bin(m, p) + Bin(n-m, q),
\end{align*}
a sum of two independent Binomial random variables with support $\{0,\dots,n\}$.
Furthermore, if $\xv\in\Dsp_m^n$ and $\xv,\xv'$ differ in one row, then $\xv'\in\Dsp_{m-1}^n \cup \Dsp_{m+1}^n$.
Defining
\[ \pi(s; m) := \frac{\P[A_n(m) = s]}{\P[A_n(m+1) = s]}
\quad\quad\text{for}\ \ 
s\in\{0,\dots,n\}\ \text{and}\ m\in\{0,\dots,n-1\},
\]
the privacy ratio becomes
\[ \pi\big((s, n-s);\,\xv,\xv'\big) =
\begin{cases}
\pi(s;m - 1) & x_1 = 1 \\[0.3em]
\inv{\pi(s;m)} & x_1 = 0
\end{cases}\, .
\]
Hence, in the $L=1$ case, it suffices to study the behaviour of $\pi(s;m)$.


\subsection{Recursive relationship over $n$ and $m$}

The conditioning argument \eqref{eq:prcond} yields a recursive relationship that lets us express the distribution of $A_n$ in terms of that of $A_{n-1}$.

Recall that $A_n(m)$ is the outcome of applying the bit transformation $R$ to $n$ original bits, $m$ of which are 1 and $n-m$ are 0.
For $m \geq 1$, we can condition on the outcome of one of the original 1s:
\[ A_n(m) \sim Ber(p) + Bin(m-1, p) + Bin(n-m, q) \sim Ber(p) + A_{n-1}(m-1), \]
and so
\begin{equation}\label{eq:rec1}
\P[A_n(m) = s] = p\P[A_{n-1}(m-1) = s-1] + q\P[A_{n-1}(m-1) = s].
\end{equation}
If $s = 0$, the first term on the RHS is interpreted as 0, and if $s = n$, the last term is.
Similarly, for $m \leq n-1$, conditioning on an original 0,
\[ A_n(m) \sim Ber(q) + Bin(m, p) + Bin(n-m-1, q) \sim Ber(q) + A_{n-1}(m), \]
from which
\begin{equation}\label{eq:rec0}
\P[A_n(m) = s] = q\P[A_{n-1}(m) = s-1] + p\P[A_{n-1}(m) = s].
\end{equation}

The recursive formulas \eqref{eq:rec1} and \eqref{eq:rec0} give some insight into how the distribution of $A_n(m)$ changes as $n$ and $m$ vary:
\begin{itemize}
\item  as $n$ increases by 1, the probabilities shift slightly, with $\P[A_n(m) = 0] \leq \P[A_{n-1}(m) = 0]$ and
$\P[A_n(m) = s]$ falling between $\P[A_{n-1}(m) = s-1]$ and $\P[A_{n-1}(m) = s]$ for each $s\geq 1$ (\ie the hump of the pmf shifts to the right);
\item the distribution of $A_n(m+1)$ is not so different to that of $A_n(m)$, since $\P[A_n(m) = s]$ and $\P[A_n(m+1) = s]$ both lie between consecutive pmf values of $A_{n-1}(m)$. In particular, this allows us to express the privacy ratio $\pi(s;m)$ in terms of $A_{n-1}(m)$.
\end{itemize}

Writing $P_{n,m}(s) := \P[A_n(m) = s]$, the formulas \eqref{eq:rec1} and \eqref{eq:rec0} can be expressed as
\[ P_{n,m}(s) = pP_{n-1,m-1}(s-1) + qP_{n-1,m-1}(s)
\quad\text{for}\ \ s = 0,\dots,n,\ \ m = 1,\dots,n \]
and
\[ P_{n,m}(s) = qP_{n-1,m}(s-1) + pP_{n-1,m}(s)
\quad\text{for}\ \ s = 0,\dots,n,\ \ m = 0,\dots,n-1. \]
We now establish a relationship between consecutive pmf values $P_{n,m}(s)$ for fixed $n$ and $m$.

\begin{prop}
For $n \geq 1$,
\begin{equation} \label{eq:recP}
(s+1) P_{n,m}(s+1) = \bigg\{ (m-s)\frac{p}{q} + (n-m-s)\frac{q}{p} \bigg\} P_{n,m}(s) + (n-s+1) P_{n,m}(s-1)
\end{equation}
for $0 \leq m \leq n$ and $0 \leq s \leq n-1$ (with $P_{n,m}(-1) := 0$).\end{prop}
\begin{pf}
We proceed by induction on $n$.
Suppose first $n=1$, $s = 0$.
If $m=1$, then $A_1(1) \sim Ber(p)$, and \eqref{eq:recP} holds since 
$(mp/q + (1-m)q/p) \cdot P_{1,1}(0) = p = P_{1,1}(1)$.
The argument is similar when $m=0$.
Next assume \eqref{eq:recP} holds for $A_{n-1}(m)$, and suppose $m \leq n-1$ and $1 \leq s \leq n-2$.
Observe that
\begin{align*}
\bigg\{ &(m-s)\frac{p}{q} + (n-m-s)\frac{q}{p} \bigg\} P_{n,m}(s) + (n-s+1) P_{n,m}(s-1) \\
&= \bigg\{ (m-s)\frac{p}{q} + (n-1-m-s)\frac{q}{p} \bigg\} \big[qP_{n-1,m}(s-1) + pP_{n-1,m}(s)\big] \\
 &\qquad\qquad + (n-1-s+1) \big[qP_{n-1,m}(s-2) + pP_{n-1,m}(s-1)\big] +
 \frac{q}{p}P_{n,m}(s) + P_{n,m}(s-1) \\
 &= p\bigg[ \bigg\{ (m-s)\frac{p}{q} + (n-1-m-s)\frac{q}{p} \bigg\} P_{n-1,m}(s) + (n-1-s+1)P_{n-1,m}(s-1) \bigg] \\
 &\qquad + q\bigg[ \bigg\{ (m-(s-1))\frac{p}{q} + (n-1-m-(s-1))\frac{q}{p} \bigg\} P_{n-1,m}(s-1) \\
 &\hspace{20em} + (n-1-(s-1)+1)P_{n-1,m}(s-2) \bigg] \\
 &\qquad - \bigg(p + \frac{q^2}{p}\bigg) P_{n-1,m}(s-1) - qP_{n-1,m}(s-2) + \frac{q^2}{p}P_{n-1,m}(s-1) + qP_{n-1,m}(s) \\
 &\qquad + qP_{n-1,m}(s-2) + pP_{n-1,m}(s-1) \\
 &= p(s+1)P_{n-1,m}(s+1) + qsP_{n-1,m}(s) + qP_{n-1,m}(s) \\
 & = (s+1) \big[ qP_{n-1,m}(s) + pP_{n-1,m}(s+1) \big] = (s+1)P_{n,m}(s+1),
\end{align*}
applying the induction hypothesis for $s$ and for $s-1$ together with \eqref{eq:rec0}. If $s=0$, the argument is similar:
\begin{align*}
\bigg\{ m\frac{p}{q} + (n-m)\frac{q}{p} \bigg\} P_{n,m}(0)
&= p\bigg\{ m\frac{p}{q} + (n-1-m)\frac{q}{p} \bigg\} P_{n-1,m}(0) + qP_{n-1,m}(0) \\
 &= pP_{n-1,m}(1) + qP_{n-1,m}(0) = P_{n,m}(1).
\end{align*}


 
\end{pf}


\subsection{Probability ratios}

(TODO) The behaviour of the privacy ratio $\pi(s;m)$ can be studied through ratios of consecutive values of the pmf $P_{n,m}(s)$.

Define the \emph{probability ratio} $\rho_n(s;m) = P_{n,m}(s) / P_{n,m}(s-1)$ for $1\leq s \leq n$. Given $m$, the probability can be expressed using \eqref{eq:recP}:
\begin{align*}
\rho(s+1;m) &= \frac{m-s}{s+1}\frac{p}{q} + \frac{n-m-s}{s+1}\frac{q}{p} + \frac{n-s+1}{s+1} \frac{1}{\rho(s;m)} \\
\rho(1;m) &= m\frac{p}{q} + (n-m)\frac{q}{p}
\end{align*}
Write
\[ \eta(s) := \frac{n-s+1}{s+1} \qquad\text{and}\qquad
\gamma_m(s) := \frac{1}{s+1} \left[(m-s)\frac{p}{q} + (n-m-s)\frac{q}{p}\right], \]
so that
\[ \rho(s+1;m) = \eta(s)\inv{\rho(s;m)} + \gamma_m(s)\,; \quad
\rho(1;m) = \gamma_m(0). \]

Note also that $\gamma_m(s)$ can be expressed in terms of $\EP A_n(m) = \mu_m = nq + m(p-q)$:
\begin{align*}
(s+1)\gamma_m(s) &= \frac{(m-s)p^2 + (n-m-s)q^2}{pq}
 = \frac{m(p^2-q^2) + nq^2 - s(p^2 + q^2)}{pq} \\
 &= \frac{nq + m(p-q) - nq + nq^2 - s(1-2pq)}{pq}
 = \frac{\mu_m - s -(n - 2s)pq}{pq} \\
 &= \frac{\mu_m - s}{pq} - n + 2s.
\end{align*} 

The probability ratio has the following properties (TODO):
\begin{itemize}
\item decreasing in $s$ for fixed $m$
\item increasing in $m$ for fixed $s$.
\end{itemize}

In addition, we are interested in the behaviour of $\rho(s;m)$ in the case where
$s$ and $m$ vary together, with $s$ maintaining a fixed distance from the mean
$\mu_m$.
Because of the discreteness, the path of $\rho$ is not monotonic.
However, we show that it is bounded by a value of $\rho(\cdot\,;0)$, if the
distance from the mean is large enough.

For $\delta > 0$ let $s_m(\delta) = \lceil \mu_m - \delta \rceil \vee 0$, and define $R_m(\delta) := \rho(s_m(\delta); m)$.
Note that $R_m(\delta) \leq R_m(\delta')$ for $\delta \leq \delta'$.

\begin{prop}
\[ R_m(\delta) \leq R_0(\delta + 1) \]
for all $m$, provided $\delta > \sigma$.
\end{prop}
\begin{pf}
Fix $\delta > 0$.
(TODO)
If $s_0(\delta) = 0$, then
$R_m(\delta) \leq \rho(0;m) \leq \rho(0;0) = R_0(\delta+1)$ by
monotonicity.

Assume $s_0(\delta) \geq 1$, and let 
$\delta' := \delta + 1 - \{\lceil \mu_0 - \delta \rceil - (\mu_0 - \delta)\} = \mu_0 - \lceil \mu_0 - \delta \rceil + 1$, \ie 
$\delta' = \inf \{\lambda : s_0(\lambda) = s_0(\delta) - 1\}$, the point between $\delta$ and $\delta + 1$ at which $s_0(\cdot)$ decrements by 1.
Then $\mu_0 - \delta'$ is an integer, and 
$s_0(\delta') = \lceil \mu_0 - \delta \rceil - 1 = s_0(\delta + 1)$.
Suppose $R_m(\delta) > R_0(\delta')$ for some $m$.
Then, we have
\[ R_0(\delta) \leq R_0(\delta') < R_m(\delta) \leq R_m(\delta'),\]
implying that
\[ \inv{R_0(\delta + 1)} = \frac{R_0(\delta) - \gamma_0(s_0(\delta+1))}{\eta(s_0(\delta+1))} > 
\frac{R_m(\delta) - \gamma_m(s_m(\delta+1))}{\eta(s_m(\delta+1))} = \inv{R_m(\delta + 1)}. \]
Since $R_m(\delta) > R_0(\delta)$ by assumption, we obtain (with $s_j := s_j(\delta+1)$):
\begin{equation}\label{eq:deltabdineq}
\big\{\eta(s_m) - \eta(s_0)\big\} R_0(\delta)
 + \big\{\eta(s_0)\gamma_m(s_m) - \eta(s_m)\gamma_0(s_0)\big\} > 0.
\end{equation}
Note that
\[ \eta(s_m) - \eta(s_0)
= \frac{n - s_m + 1}{s_m + 1} - \frac{n - s_0 + 1}{s_0 + 1}
= -\frac{(n + 2)(s_m - s_0)}{(s_0 + 1)(s_m + 1)}, \]
and
\begin{align*}
\eta(s_0)&\gamma_m(s_m) - \eta(s_m)\gamma_0(s_0) \\
&= \frac{n - s_0 + 1}{s_0 + 1}\cdot \frac{(\mu_m - s_m)/pq - n + 2s_m}{s_m + 1} - 
\frac{n - s_m + 1}{s_m + 1}\cdot \frac{(\mu_0-s_0)/ pq - n + 2s_0}{s_0 + 1} \\
 &= \frac{(n+2)(s_m-s_0) + (\mu_0 s_m - \mu_m s_0)/pq + (n+1)[\mu_m - \mu_0 - (s_m - s_0)]/pq}{(s_0 + 1)(s_m + 1)}.
\end{align*}

Now, write $\delta' := \delta - \{\lceil \mu_0 - \delta \rceil - (\mu_0 - \delta)\} = \mu_0 - \lceil \mu_0 - \delta \rceil$, so that
$s_0 = \mu_0 - \delta' - 1$.
Then
\begin{align*}
 \mu_0 s_m - \mu_m s_0 &= \mu_0(s_m - s_0) + \mu_0(\mu_0 - \delta' - 1) - (\mu_0 + m(p-q))(\mu_0 - \delta' - 1) \\
 &= \mu_0(s_m - s_0) - m(p-q)(\mu_0 - \delta' - 1).
\end{align*}


Applying these in \eqref{eq:deltabdineq} gives
\begin{align*}
0 < (n+2)(s_m-s_0)\big[1- R_0(\delta)\big] + \frac{\mu_0 s_m - \mu_m s_0}{pq} + (n+1)\frac{\mu_m - \mu_0 - (s_m - s_0)}{pq}
\end{align*}

\end{pf}


----------------------------


\subsection{Recursive relationship for CDFs}

Summing both sides of \eqref{eq:rec1} and \eqref{eq:rec0} shows that the recursive relationship extends to cdfs as well.
Writing $F_{n,m}(x) := \P[A_n(m) \leq x]$, we have
\begin{equation*}%\label{eq:Frec1}
F_{n,m}(x) = p\cdot F_{n-1,m-1}(x-1) + q\cdot F_{n-1,m-1}(x)
\qquad\qquad m = 1,\dots,n
\end{equation*}
and 
\begin{equation*}%\label{eq:Frec0}
F_{n,m}(x) = q\cdot F_{n-1,m}(x-1) + p\cdot F_{n-1,m}(x)
\qquad\qquad m = 0,\dots,n-1.
\end{equation*}

Furthermore, we can express the difference on incrementing $m$ as follows:
\begin{align*}
 F_{n,m}(x) &- F_{n,m-1}(x) \\
&= p F_{n-1,m-1}(x-1) + q F_{n-1,m-1}(x) - q F_{n-1,m-1}(x-1)
 - p F_{n-1,m-1}(x) \\
&= (p-q) \big[ F_{n-1,m-1}(x-1) - F_{n-1,m-1}(x) \big] \\
&= -(p-q) P_{n-1, m-1}(\lfloor x \rfloor)
\end{align*}
and
\begin{align*}
 F_{n,m}(x+1) &- F_{n,m-1}(x) \\
&= p F_{n-1,m-1}(x) + q F_{n-1,m-1}(x+1) - q F_{n-1,m-1}(x-1)
 - p F_{n-1,m-1}(x) \\
&= q\big[ F_{n-1,m-1}(x+1) - F_{n-1,m-1}(x-1) \big] \\
&= q\big\{ P_{n-1, m-1}(\lfloor x \rfloor) +
P_{n-1, m-1}(\lfloor x+1 \rfloor) \big\}
\end{align*}

Therefore, $F_{n,m}(x) \leq F_{n,m-1}(x) \leq F_{n,m}(x+1)$ and $F_{n,m-1}(x-1) \leq F_{n,m}(x) \leq F_{n,m-1}(x)$.

For probabilities, the relationship becomes
\[
P_{n, m}(s) - P_{n, m-1}(s) = -(p-q) \big\{ P_{n-1, m-1}(s) - P_{n-1, m-1}(s-1) \big\}
\]
and
\[
P_{n, m}(s+1) - P_{n, m-1}(s) = q \big\{ P_{n-1, m-1}(s+1) - P_{n-1, m-1}(s-1) \big\}.
\]


\subsection{Privacy Ratio}

Using the recursive relationships \eqref{eq:rec1} and \eqref{eq:rec0}, we have
\[ \pi(s; m) = \frac{\P[A_n(m) = s]}{\P[A_n(m+1) = s]}
 = \frac{q P_{n-1, m}(s-1) + p P_{n-1, m}(s)}
 {p P_{n-1, m}(s-1) + q P_{n-1, m}(s)}.
\]
Lemma \ref{lem:rscomp2} implies that monotonicity and extrema of  the privacy ratio $\pi$ are determined by those of the \emph{probability ratio} $P_{n-1, m}(s)/P_{n-1,m}(s-1)$:
\[ \text{if}\quad \frac{P_{n-1,m}(s)}{P_{n-1,m}(s-1)} \geq \frac{P_{n-1,m'}(s')}{P_{n-1,m'}(s'-1)},
\quad\text{then}\quad \pi_n(s;m) \geq \pi_n(s';m'). \]
Hence, studying the behaviour of the privacy ratio reduces to studying 
ratios of consecutive pmf values.
Using this property, we can derive the following facts:
\begin{itemize}
\item $\pi$ is decreasing in $s$: $\pi(s;m) \geq \pi(s+1; m)$
\item $\pi$ is increasing in $m$: $\pi(s;m) \leq \pi(s; m+1)$
\item $\pi$ is net decreasing when both $s$ and $m$ increase:
$\pi(s;m) \geq \pi(s+1; m+1)$.
\end{itemize}

A different approach, using the difference identities above, gives
\begin{align*}
\pi(s; m) &= \frac{P_{n,m}(s)}{P_{n,m+1}(s)}
 = \frac{P_{n,m-1}(s) + (p-q)\{P_{n-1,m-1}(s-1) - P_{n-1,m-1}(s)\}}
 {P_{n,m}(s) + (p-q)\{P_{n-1,m}(s-1) - P_{n-1,m}(s)\}} \\
 &= \frac{\frac{P_{n,m-1}(s)}{P_{n,m}(s)} + (p-q)\frac{P_{n-1,m-1}(s-1) - P_{n-1,m-1}(s)}{P_{n,m}(s)}}
 {1 + (p-q)\frac{P_{n-1,m}(s-1) - P_{n-1,m}(s)}{P_{n,m}(s)}}.
\end{align*}
Therefore,
\begin{align*}
\frac{\pi(s; m)}{\pi(s; m-1)} &= \frac{P_{n,m}(s)}{P_{n,m-1}(s)} \pi(s;m) \\
 &= \frac{1 + (p-q)\frac{P_{n-1,m-1}(s-1) - P_{n-1,m-1}(s)}{P_{n,m-1}(s)}}
 {1 + (p-q)\frac{P_{n-1,m}(s-1) - P_{n-1,m}(s)}{P_{n,m}(s)}}
\end{align*}


\subsection{Quantiles}

Denote by $\tau_n(m)$ the $\alpha$-th quantile of $F_{n,m}$:
\[ \tau_n(m) = \inf\{y : F_{n,m}(y) \geq \alpha \}. \]
Note that $\tau_n(m)$ is an integer satisfying $F_{n,m}(\tau_n(m)) \geq \alpha$ and $F_{n,m}(\tau_n(m) - 1) < \alpha$.

\begin{claim}
For $m = 1,\dots,n$,
\[ \tau_n(m) \in \{ \tau_n(m-1), \tau_n(m-1) + 1 \}. \]
\end{claim}
\begin{pf}
Since $\alpha \leq F_{n,m}(\tau_n(m)) \leq F_{n,m-1}(\tau_n(m))$, we have $\tau_n(m) \geq \tau_n(m-1)$.
On the other hand, $F_{n,m}(\tau_n(m-1)+1) \geq F_{n,m-1}(\tau_n(m-1)) \geq \alpha$, from which $\tau_n(m) \leq \tau_n(m-1) + 1$.
\end{pf}

Furthermore, $\tau_n(m) = \tau_n(m-1)$ if and only if
$F_{n,m}(\tau_n(m-1)) \geq \alpha$, \ie
\[ F_{n,m-1}(\tau_n(m-1)) - \alpha \geq (p-q)\P[A_{n-1}(m-1) = \tau_n(m-1)]. \]



\subsection{Asymptotic approach}

    



\subsection{Approximate location relationship over $m$}

The family $\{A_n(m),\, m = 0,\dots,n\}$ are in fact approximately location-shifted versions of each other.
Indeed, note that
\[ \EP A_n(m) = mp + (n-m)q = nq + m(p-q) \]
and
\[ \Var A_n(m) = mpq + (n-m)qp = npq. \]
In other words, as $m$ varies between $0$ and $n$, the mean varies linearly in $m$ and the variance remains constant.
The central portion of the distribution remains approximately the same shape, although transitioning from right-skewed when $m=0$ to left-skewed when $m=n$.
Thus, 
\[ F_{n,m}(x) \approx F_{n,0}(x - m(p-q)). \]

We quantify this approximation as follows.


\section{Maximal collections}


The first question we address is for which pair of original and modified collections $\xv$ and $\xv'$ does $\pi$ obtain its maximum.

\subsection{The case $L = 1$}

It is instructive to first consider the case where each record in the collection consists of a single bit, as the expressions simplify considerably.
In this case, the outcome of $A$ essentially reduces to the number of 1s obtained in the synthetic collection $R(\xv)$, since $\sv\in\Ssp_n$ can be written as $(s_1,s_2)$ with $s_1\in\{0,\dots,n\}$ and $s_2 = n-s_1$. 
Using this fact, we interpret $A(\xv)$ as $\sum_{i=1}^n I(R(x_i) = 1)$,
and express the privacy ratio as
\[ \pi(s,\xv,x_1') = \frac{\P[R(x'_1) = 1] \P[A(\xvt) = s-1] +
\P[R(x'_1) = 0] \P[A(\xvt) = s]}
{\P[R(x_1) = 1] \P[A(\xvt) = s-1] + \P[R(x_1) = 0] \P[A(\xvt) = s]}
\]
for $s \in \{0,\dots,n\}$. Furthermore, the requirement that $x_1 \neq x'_1$ in the single-bit case implies that $x'_1 = 1-x_1$, so
\[ \pi(s,\xv,x_1') = \frac{(1-\P[R(x_1) = 1]) \P[A(\xvt) = s-1] +
(1-\P[R(x_1) = 0]) \P[A(\xvt) = s]}
{\P[R(x_1) = 1] \P[A(\xvt) = s-1] + \P[R(x_1) = 0] \P[A(\xvt) = s]}.
\]
%Hence, $\pi(s; x_1 = 0) = 1/\pi(s; x_1 = 1)$, and so 
%\[ \max_{\xv,\xv';\,\sv} \pi = \max\left(\max_{\xvt;\,s} \pi(s;x_1 = 1),\, \max_{\xvt;\,s} \pi(s;x_1 = 0)\right)
%=  \max\left(\max_{\xvt;\,s} \pi(s;x_1 = 1),\, \min_{\xvt;\,s} \pi(s;x_1 = 1)\right)
%\]
We fix $s \in \{1,\dots,n\}$ and investigate which choice of collection $\xv = (x_1,\xvt)$ maximizes $\pi(s,\xv,x_1')$.
Assume first $x_1 = 1$. (TODO: what about when $x_1 = 0$?) Then
\[ \pi(s,\xvt,0) = \frac{q \P[A(\xvt) = s-1] + p \P[A(\xvt) = s]}
{p \P[A(\xvt) = s-1] + q \P[A(\xvt) = s]}.
\]
By Lemma \ref{lem:rscomp2}, this ratio is maximized at $\xvt^*$ satisfying 
\[ \frac{\P[A(\xvt^*) = s]}{\P[A(\xvt^*) = s-1]} \geq
\frac{\P[A(\yvt) = s]}{\P[A(\yvt) = s-1]} \]
for any $\yvt \in \Dsp^{n-1}$.
We claim that this is the case when $\xvt^*$ consists of all 1s:
%%% Claim to be proven by induction.
\begin{claim}
Write $\one = (1,...,1)$ as an element of $\Dsp^n$.
Then, given $s \in \{1,\dots,n\}$,
\begin{equation} \label{eq:maxpA}
\frac{\P[A(\one) = s]}{\P[A(\one) = s-1]} \geq
\frac{\P[A(\yv) = s]}{\P[A(\yv) = s-1]}
\end{equation}
for any $\yv \in \Dsp^n$.
\end{claim}
\begin{pf}
We proceed by induction on $n$. If $n = 1$, then $A(x) = R(x)$, we need only confirm \eqref{eq:maxpA} for $s = 1$.
Taking $\yv = 0$ (the only possibility aside from $\one$), we have
\begin{equation} \label{eq:singleratio}
\frac{\P[R(0) = 1]}{\P[R(0) = 0]} = \frac{q}{p} \leq
\frac{p}{q} = \frac{\P[R(1) = 1]}{\P[R(1) = 0]}
\end{equation}
verifying \eqref{eq:maxpA} in this case.
Next, suppose that \eqref{eq:maxpA} holds for $s\in\{1,\dots,n-1\}$ and $\one,\yvt \in \Dsp^{n-1}$, and consider $\yv = (\yvt, y_n) \in \Dsp^n$.
For convenience, write $p(y_n) = \P[R(y_n) = 1]$. 
Observe that
\[ \P[A(\yv) = s] = \P[A(\yvt) = s]\cdot(1-p(y_n)) +
\P[A(\yvt) = s-1]\cdot p(y_n), \]
conditioning on the value of $y_n$.
Thus,
%for $s \in \{2,\dots,n-1\}$,
\begin{equation} \label{eq:inductionratio}
\frac{\P[A(\yv) = s]}{\P[A(\yv) = s-1]}
= \frac{\P[A(\yvt) = s]\cdot(1-p(y_n)) +
\P[A(\yvt) = s-1]\cdot p(y_n)}
{\P[A(\yvt) = s-1]\cdot(1-p(y_n)) +
\P[A(\yvt) = s-2]\cdot p(y_n)}.
\end{equation}
For $s \in \{2,\dots,n-1\}$, our induction hypothesis implies that
\[
\frac{\P[A(\yvt) = s]}{\P[A(\yvt) = s-1]} \leq
\frac{\P[A(\one) = s]}{\P[A(\one) = s-1]}\quad\text{and}\quad
\frac{\P[A(\yvt) = s-1]}{\P[A(\yvt) = s-2]} \leq
\frac{\P[A(\one) = s-1]}{\P[A(\one) = s-2]},
\]
and furthermore,
\[ \frac{\P[A(\yvt) = s]}{\P[A(\yvt) = s-2]} =
\frac{\P[A(\yvt) = s]}{\P[A(\yvt) = s-1]}\cdot
\frac{\P[A(\yvt) = s-1]}{\P[A(\yvt) = s-2]} \leq
\frac{\P[A(\one) = s]}{\P[A(\one) = s-2]}.
\]
Therefore, we can apply Lemma \ref{lem:rscomp} to \eqref{eq:inductionratio} to obtain
\begin{equation} \label{eq:lemmaappl}
\frac{\P[A(\yv) = s]}{\P[A(\yv) = s-1]} \leq
\frac{\P[A(\one) = s]\cdot(1-p(y_n)) +
\P[A(\one) = s-1]\cdot p(y_n)}
{\P[A(\one) = s-1]\cdot(1-p(y_n)) +
\P[A(\one) = s-2]\cdot p(y_n)}
%= \frac{\P[A((\one,y_n)) = s]}{\P[A((\one,y_n)) = s-1]}
\end{equation}
for $s \in \{2,\dots,n-1\}$.
If $s = n$, we consider $\P[A(\yvt) = s] = 0$ since
$\P[A(\yvt) \in \{0,\dots,n-1\}] = 1$, and similarly for $\P[A(\one) = s]$.
In this case, Lemma \ref{lem:rscomp} still applies with $b=b'=0$.
A similar argument establishes \eqref{eq:lemmaappl} when $s = 1$.
Therefore,
\[
\frac{\P[A(\yv) = s]}{\P[A(\yv) = s-1]} \leq
\frac{\P[A((\one,y_n)) = s]}{\P[A((\one,y_n)) = s-1]}
\]
for $s \in \{1,\dots,n\}$.
Since $y_n\in\{0,1\}$, the proof will be complete if we show that
\begin{align}
\frac{\P[A((\one,1)) = s]}{\P[A((\one,1)) = s-1]} &=
\frac{\P[A(\one) = s]\cdot q +
\P[A(\one) = s-1]\cdot p}
{\P[A(\one) = s-1]\cdot q +
\P[A(\one) = s-2]\cdot p} \nonumber\\
&\geq
\frac{\P[A(\one) = s]\cdot p +
\P[A(\one) = s-1]\cdot q}
{\P[A(\one) = s-1]\cdot p +
\P[A(\one) = s-2]\cdot q}
= \frac{\P[A((\one,0)) = s]}{\P[A((\one,0)) = s-1]}.
\label{eq:indfinal}
\end{align}
Using the fact that $A(\one) \sim Bin(n-1, p)$, observe that
\[
\frac{\P[A(\one) = s]}{\P[A(\one) = s-1]}
= \frac{\binom{n-1}{s}p^{s}q^{n-1-s}}{\binom{n-1}{s-1}p^{s-1}q^{n-s}}
= \frac{n-s}{s}\frac{p}{q},
\]
from which
\[
\frac{\lambda_2}{\mu_2} = \frac{\P[A(\one) = s]}{\P[A(\one) = s-1]}
= \frac{n-s}{s}\frac{p}{q} \leq \frac{n-s+1}{s-1}\frac{p}{q}
= \frac{\P[A(\one) = s-1]}{\P[A(\one) = s-2]} = \frac{\lambda_1}{\mu_1},
\]
and hence \eqref{eq:indfinal} follows from Lemma \ref{lem:rscomp2} (unless $s=1$, in which case it follows from a simple direct argument).
\end{pf}
TODO: finish argument in the case when $x_1 = 0$.    

\section{Ratios of sums: properties}

Here we establish some results around bounding and comparing ratios of sums, which will be useful in working with the privacy ratio.

%%% Bounding ratio of sums by max ratio of terms

\begin{lem} \label{lem:rsbound}
Suppose $a_1,\dots,a_m,b_1,\dots,b_m \in \R$ with $b_i > 0$ all $i$.
Then 
\[ \frac{a_1 + \cdots + a_m}{b_1 + \cdots + b_m} \leq
\max\left(\frac{a_1}{b_1},\dots,\frac{a_m}{b_m}\right). \]
\end{lem}
\begin{pf}
Write
\[ \frac{a_1 + \cdots + a_m}{b_1 + \cdots + b_m}
= \frac{a_1}{b_1}\frac{b_1}{b_1+\cdots+b_m} +
%\frac{a_2}{b_2}\frac{b_2}{b_1+\cdots+b_m} +
\cdots + \frac{a_m}{b_m}\frac{b_m}{b_1+\cdots+b_m} =
\sum_{i=1}^m \frac{a_i}{b_i} \lambda_i
\]
where $\lambda_1 + \cdots + \lambda_m = 1$.
The result follows since each $a_i/b_i$ is bounded by $\max_i a_i/b_i$.
\end{pf}

%%% Comparing ratios of sums by comparing ratios of terms

%\begin{lem} \label{lem:rscomp}
%Suppose $a_i,b_i,a'_i,b'_i > 0$ for $i=1,\dots,m$.
%Then
%\begin{equation} \label{eq:rscomp}
%\frac{a_1 + \cdots + a_m}{b_1 + \cdots + b_m} \geq
%\frac{a'_1 + \cdots + a'_m}{b'_1 + \cdots + b'_m}
%\end{equation}
%if
%\begin{equation} \label{eq:lambdamucond}
%a_i/b_i \geq  a_j/b_j,\quad a'_i/b'_i \geq a'_j/b'_j
%\end{equation}
%and
%\begin{equation} \label{eq:aapcond}
%a_i/a_j \geq a'_i/a'_j,\quad b_i/b_j \geq b'_i/b'_j
%\end{equation}
%whenever $1 \leq i < j \leq m$.
%\end{lem}
%It is easy to see that \eqref{eq:lambdamucond} is satisfied when
%$a_1 \geq a_2 \geq \cdots \geq a_m$ and $b_1 \leq b_2 \leq \cdots \leq b_m$, and analogously for $a'$ and $b'$.
%It is also clear from the proof that \eqref{eq:rscomp} still holds if all the inequalities in \eqref{eq:lambdamucond} and \eqref{eq:aapcond} are reversed.
%\begin{pf}
%Cross-multiplying, we see that \eqref{eq:rscomp} is equivalent to
%\[ \sum_i \sum_j a_i b'_j \geq \sum_i \sum_j a'_i b_j \iff
%\sum_i \sum_{j \neq i} (a_ib'_j - a'_ib_j) \geq 0.
%\]
%Furthermore,
%\begin{align*}
%\sum_i \sum_{j \neq i} (a_ib'_j - a'_ib_j)
%&= \sum_i \sum_{j > i} (a_ib'_j - a'_ib_j) +
%\sum_i \sum_{j < i} (a_ib'_j - a'_ib_j) \\
%% relabel the indices
%&= \sum_i \sum_{j > i} a_i a'_j (\lambda_i\mu_j - \lambda_j\mu_i) +
%\sum_j \sum_{i < j} a_j a'_i (\lambda_j\mu_i - \lambda_i\mu_j) \\
%% reverse the sums
%&= \sum_i \sum_{j > i} a_i a'_j (\lambda_i\mu_j - \lambda_j\mu_i) +
%\sum_i \sum_{j > i} a_j a'_i (\lambda_j\mu_i - \lambda_i\mu_j) \\
%%% factor out -1 from the second term and combine
%&= \sum_i \sum_{j > i} (a_i a'_j - a_j a'_i)(\lambda_i\mu_j - \lambda_j\mu_i),
%\end{align*}
%where the second equality follows from relabeling the summation indices, and the third from reversing the sums.
%It follows that \eqref{eq:rscomp} will hold if
%$(a_i a'_j - a_j a'_i)(\lambda_i\mu_j - \lambda_j\mu_i) \geq 0$ for all  $1 \leq i < j \leq m$, which is implied by \eqref{eq:lambdamucond} and \eqref{eq:aapcond}.
%\end{pf}


%%%%%%%%%%%%%%%%%%%%

\begin{lem} \label{lem:rscomp2}
Suppose $a_i,a'_i,\lambda_i,\mu_i > 0$ for $i=1,\dots,m$.
Then
\begin{equation} \label{eq:rscomp2}
\frac{a_1\lambda_1 + \cdots + a_m\lambda_m}
{a_1\mu_1 + \cdots + a_m\mu_m} \geq
\frac{a'_1\lambda_1 + \cdots + a'_m\lambda_m}
{a'_1\mu_1 + \cdots + a'_m\mu_m}
\end{equation}
if
\begin{equation} \label{eq:lambdamucond2}
\lambda_i/\mu_i \geq  \lambda_j/\mu_j
% \frac{\lambda_i}{\mu_i} \geq \frac{\lambda_j}{\mu_j}
%\quad\quad\text{and}\quad\quad \frac{a_i}{a_j} \geq \frac{a'_i}{a'_j}
\end{equation}
and
\begin{equation} \label{eq:aapcond2}
a_i/a_j \geq a'_i/a'_j
\end{equation}
whenever $1 \leq i < j \leq m$.
\end{lem}
Note that numerator and denominator have the same index \eqref{eq:lambdamucond2}, and different indices in \eqref{eq:aapcond2}.
It is easy to see that \eqref{eq:lambdamucond2} is satisfied when
$\lambda_1 \geq \lambda_2 \geq \cdots \geq \lambda_m$ and
$\mu_1 \leq \mu_2 \leq \cdots \leq \mu_m$.
It is also clear from the proof that \eqref{eq:rscomp2} still holds if all the inequalities in \eqref{eq:lambdamucond2} and \eqref{eq:aapcond2} are reversed.
An important special case for us is the following:
\begin{cor}
Suppose $0 < q < p < 1$ and $a_i, a'_i > 0$ for $i = 1,2$.
Then
\[ \frac{q \cdot a_1 + p\cdot a_2}{p\cdot a_1 + q\cdot a_2} \geq
\frac{q\cdot a'_1 + p\cdot a'_2}{p\cdot a'_1 + q\cdot a'_2} \]
whenever
\[ \frac{a_2}{a_1} \geq \frac{a'_2}{a'_1}. \]
\end{cor}
\begin{pf}
Cross-multiplying, we see that \eqref{eq:rscomp2} is equivalent to
\[ \sum_i \sum_j a_i a'_j \lambda_i \mu_j \geq
\sum_i \sum_j a_i a'_j \lambda_j \mu_i \iff
\sum_i \sum_{j \neq i} a_i a'_j (\lambda_i\mu_j - \lambda_j\mu_i) \geq 0.
\]
Furthermore,
\begin{align*}
\sum_i \sum_{j \neq i} a_i a'_j (\lambda_i\mu_j - \lambda_j\mu_i)
&= \sum_i \sum_{j > i} a_i a'_j (\lambda_i\mu_j - \lambda_j\mu_i) +
\sum_i \sum_{j < i} a_i a'_j (\lambda_i\mu_j - \lambda_j\mu_i) \\
%% relabel the indices
&= \sum_i \sum_{j > i} a_i a'_j (\lambda_i\mu_j - \lambda_j\mu_i) +
\sum_j \sum_{i < j} a_j a'_i (\lambda_j\mu_i - \lambda_i\mu_j) \\
%% reverse the sums
&= \sum_i \sum_{j > i} a_i a'_j (\lambda_i\mu_j - \lambda_j\mu_i) +
\sum_i \sum_{j > i} a_j a'_i (\lambda_j\mu_i - \lambda_i\mu_j) \\
%% factor out -1 from the second term and combine
&= \sum_i \sum_{j > i} (a_i a'_j - a_j a'_i)(\lambda_i\mu_j - \lambda_j\mu_i),
\end{align*}
where the second equality follows from relabeling the summation indices, and the third from reversing the sums.
It follows that \eqref{eq:rscomp2} will hold if
$(a_i a'_j - a_j a'_i)(\lambda_i\mu_j - \lambda_j\mu_i) \geq 0$ for all  $1 \leq i < j \leq m$, which is implied by \eqref{eq:lambdamucond2} and \eqref{eq:aapcond2}.
\end{pf}

\begin{lem} \label{lem:rscomp}
Suppose $a,a',\lambda,\mu > 0$, and $b,b',c,c'\geq 0$. Then
\begin{equation} \label{eq:lemrscomp}
 \frac{a\lambda + b\mu}{c\lambda + a\mu} \geq
\frac{a'\lambda + b'\mu}{c'\lambda + a'\mu}
\end{equation}
if
\begin{equation} \label{eq:abccond}
ac' \geq a'c,\quad ab' \leq a'b,\quad\text{and}\quad bc' \geq b'c.
\end{equation}
\end{lem}
\begin{pf}
\eqref{eq:lemrscomp} holds iff
\begin{align*}
 ac'\lambda^2 &+ aa'\lambda\mu + bc'\lambda\mu + a'b\mu^2 \geq
a'c\lambda^2 + b'c\lambda\mu + aa'\lambda\mu + ab'\mu^2 \\
&\iff (ac'-a'c)\lambda^2 + (bc'-b'c)\lambda\mu + (a'b-ab')\mu^2 \geq 0,
\end{align*}
which is implied by \eqref{eq:abccond}.
\end{pf}


\section{Old stuff}


%%% Independent randomization/RAPPOR form of DP

%% To prove in general (for sets other than measurable rectangles, represent
%% probability as an iterated integral over sections - only one will be different.

Furthermore, if $A$ randomizes each record in the database independently,
\ie $A(\boldsymbol{x}) = A(\boldsymbol{x}, \boldsymbol{X}) := 
\big(A_0(x_1, X_1),\dots,A_0(x_n,X_n)\big)$
where $X_i$ are independent,
then $\boldsymbol{S} = \boldsymbol{S}_0^n$ and $s = (s_1,\dots,s_n)$ with 
$s_i \in \boldsymbol{S}_0$. 
In this case
$P[A(\boldsymbol{x}) = s] = P[A_0(x_1) = s_1,\dots,A_0(x_n) = s_n]
= \prod P[A_0(x_i) = s_i]$.
If $\boldsymbol{x}$ and $\boldsymbol{x'}$ differ in one row (wlog $x_1 \neq x'_1$ and $x_i = x'_i$ for $i = 2,\dots,n$),
then
\[ \frac{P[A(\boldsymbol{x}) = s]}{P[A(\boldsymbol{x'}) = s]} = 
\frac{P[A_0(x_1) = s_1]}{P[A_0(x'_1) = s_1]}. \]
Therefore, in this case, the query $A$ will satisfy differential privacy if
\[ P[A_0(x) = s] \leq \epsilon \cdot P[A_0(x') = s] \]
for all $x,x' \in D$ and $s \in \boldsymbol{S}_0$.
This is the formulation used in the RAPPOR paper that applies to differences between individual records rather than collections differing on a single element.




\end{document}















