%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 
%% Informal notes on k-randomization.
%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass[11pt,draft]{article}
%\documentclass[11pt,draft]{amsart}

%% Custom styling.
\usepackage{mozdp}
%% Controls enumeration labels
%\usepackage{enumerate}
%% Shrinks margins 
\usepackage{fullpage}
%% Shows equation label keys
%\usepackage[notref]{showkeys}

%% Some convenience aliases.
\newcommand{\Dsp}{\mathcal{D}}
\newcommand{\Ssp}{\mathcal{S}}
\newcommand{\xv}{\mathbf{x}}
\newcommand{\yv}{\mathbf{y}}
\newcommand{\sv}{\mathbf{s}}
\newcommand{\xvt}{\tilde{\xv}}
\newcommand{\sm}{\sv^-}
\newcommand{\iv}{\mathbf{i}}

%% Title matter
\title{K-Randomization}
\author{Maxim Zhilyaev \and David Zeber}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\maketitle

\section{Differential Privacy}
\label{sec:dp}

The typical setting for differential privacy is as follows. 
We consider a \textbf{database} as a collection of records. 
Each record is an element of some space $\Dsp$, and a database $\xv$ is a vector of $n$ records: $\xv = (x_1,\dots,x_n) \in \Dsp^n$.

We wish to release information retrieved from the database by means of a \textbf{query}, a function $A$ mapping the database into another space: $\map{A}{\Dsp^n}{\Ssp}$. The result of applying a query to a database is termed a \textbf{transcript}.
The query usually applies some aggregation to the database records, and so the output space $\Ssp$ is generally of lower dimensionality than the original database.
If the query is randomized, \ie $A(\xv) = A(\xv; \xi)$ for a random element $\xi$, then the transcript will be a random element of $\Ssp$.

The notion of differential privacy for a database query is that the resulting transcript does not change substantially when a record in the database is modified,
\ie transcripts are not sensitive to particular individual records in the database.
Hence, releasing query transcripts publicly will not jeopardize privacy, since information regarding individual records cannot be gained by analyzing query transcripts.

%%% Differential privacy definition

Differential privacy for a randomized query $A$ is formulated by comparing the transcripts generated by applying $A$ to two very similar databases $\xv,\xv' \in \Dsp^n$.
We say the databases \textbf{differ in one row} if 
$\sum_{i=1}^n I(x_i \neq x'_i) = 1$.
\begin{defn}
A randomized query $A$ is $\epsilon$-\textbf{differentially private} if, 
for any two databases $\xv,\xv' \in \Dsp^n$ differing in one row,
\begin{equation}\label{eq:dpdef}
\P[A(\xv) \in S] \leq \exp(\epsilon) \cdot \P[A(\xv') \in S]
\end{equation}
for all $S \cont \Ssp$ (measurable).
\end{defn}
In other words, the transcripts from the two databases databases differing in one row are close in distribution.
An alternative notion of differing in one row that is sometimes used is that $\xv'$ includes an additional record that is not in $\xv$:
$\xv\in \Dsp^n$, $\xv' \in \Dsp^{n+1}$, and $x_i = x'_i$ for $i = 1,\dots,n$.

%%% Countable output space

%% TODO: countable vs. finite
%% TODO: Lemma for bounding ratio of sums

If $\Ssp$ is finite, which is common in cases where the transcript involves integer counts, then the distribution of the transcript $A(\xv)$ can be represented using its pmf $\P[A(\xv) = s]$ for $s \in \Ssp$.
In this case, the differential privacy condition can also be expressed in terms of the pmf.
\begin{prop} \label{prop:dpcnt}
If $\Ssp$ is finite, then $A$ is $\epsilon$-\textbf{differentially private} if and only if
\begin{equation} \label{eq:dpcnt}
\P[A(\xv) = s] \leq \exp(\epsilon) \cdot \P[A(\xv') = s]
\end{equation}
for all $s\in\Ssp$, where $\xv,\xv'$ differ in one row.
\end{prop}
\begin{pf}
\pfleftdir
Given $S \cont \Ssp$, we can write
$\P[A(\xv) \in S] = \sum_{s \in S} \P[A(\xv) = s]$.
If $\P[A(\xv') \in S] = 0$, then $\P[A(\xv') = s] = 0$ for each $s \in S$.
From \eqref{eq:dpcnt} we have that $\P[A(\xv) = s] = 0$ as well, and so $P[A(\xv) \in S] = 0$, verifying \eqref{eq:dpdef}.
Otherwise, if $\P[A(\xv') \in S] > 0$,
\[ \frac{\P[A(\xv) \in S]}{\P[A(\xv') \in S]}
= \frac{\sum_{s \in S} \P[A(\xv) = s]}{\sum_{s \in S} \P[A(\xv') = s]}
\leq \max_{s \in S} \frac{\P[A(\xv) = s]}{\P[A(\xv') = s]}
\leq \exp(\epsilon), \]
using Lemma (need ref).\\
\pfrightdir Take $S = \{s\}$ in \eqref{eq:dpdef}.
\end{pf}



\section{Bit vector reporting}

Our goal is to establish differential privacy properties for user data reported in the form of vectors of bits.
To protect user privacy, each user record is randomized prior to leaving the client and anonymized on reaching the server.
We now describe the randomization procedure, and place ourselves in the setting of Section \ref{sec:dp} by representing it as a query applied to a database.


\subsection{Bit randomization}

For our purposes, a \textbf{bit} is an integer $b \in \{0,1\}$, and a \textbf{bit vector} is a vector $x \in \{0,1\}^L$.
Bits and bit vectors are randomized in the following way.

\begin{defn}
The \textbf{bit randomization} procedure $R$ with \textbf{lie probability} $0 < q < 1/2$ flips a bit $b$ with probability $q$, and leaves it as-is with probability $p := 1-q$:
\[ R(b) =
\begin{cases}
b & \text{with prob }p \\
1-b & \text{with prob }q
\end{cases}.
\]
This can be expressed concisely as
\[ R(b) = R(b; \xi) = b \cdot \xi + (1-b) \cdot (1-\xi)
\quad\text{where } \xi\sim Ber(p). \]
We extend the procedure to \textbf{bit vector randomization} by applying the randomization independently to each bit in the vector.
Given a bit vector $x = (b_1,\dots,b_L)$, define
\[ R(x) = R(x;\xi) = \big(R(b_1;\xi_1), \dots, R(b_L;\xi_L)\big)
\quad\text{where } \xi = (\xi_1,\dots,\xi_L) \iid Ber(p). \]
\end{defn}

\begin{rmk}
Note that $R$ reports the original bit value with probability $p = 1-q > q$, and lies with probability $q$.
This is equivalent to the randomized response procedure where the value is reported as-is with probability $1-f$, and with probability $f$ the reported value is the outcome of the toss of a fair coin.
In our case, $q = f/2$.
\end{rmk}
\begin{rmk}
If $q = 1/2$, then $R(0)\eqdist R(1)$, and the reported value is ``completely'' randomly generated, \ie independently of the original value.
\end{rmk}

%%% Distribution of randomized bit vectors.

We now consider the distribution of the randomized bit vectors.
It can be expressed in terms of the Hamming distance between the original and randomized vectors:
\[ \delta(x,x') = \sum_{\ell = 1}^L I(x_\ell \neq x'_\ell)
= \sum_{\ell = 1}^L |x_\ell - x'_\ell|. \]
For a single bit, the randomization has lied when the outcome is different from the original value: 
\[ \P[R(b) = y] = p^{I(b = y)}\cdot q^{I(b \neq y)}
= (1-q)^{1 - \delta(b,y)}\cdot q^{\delta(b,y)}. \]
For a bit vector $x$, this becomes
\[ \P[R(x) = y] = p^{\sum I(x_\ell = y_\ell)}\cdot q^{\sum I(x_\ell \neq y_\ell)}
= (1-q)^{L-\delta(x,y)}\cdot q^{\delta(x,y)}.
\]
Note that this probability is maximized when $\delta(x,y) = 0$ (the randomized vector $y$ is identical to the original vector $x$), and minimized when $\delta(x,y) = L$.
In the latter case, we say that $y$ is the \textbf{opposite} of $x$.
In other words, the most likely outcome of randomizing a bit vector is obtaining an identical vector.

\subsection{Reporting for bit records}

We now place ourselves in the setting of Section \ref{sec:dp} for bit-vector user records, as required in the sequel.

Set $\Dsp = \{0,1\}^L$. We use the term \textbf{collection} (of records) interchangeably with ``database''.
We consider a randomized query $A$ that randomizes each record in the collection independently, and aggregates the results by reporting occurrence counts for every possible randomization outcome.
We adopt this aggregation step as a model for anonymization. After anonymization, any link to the original collection or ordering is lost, and the information contained in the results is embodied solely by the reported values.

In the following, we rely on the fact that $\Dsp$ is finite, and we assume a specific enumeration $\Dsp = (d_1,\dots,d_{2^L})$. The ordering is unimportant at this point, although it will be convenient to assume that $d_1 =  (1,\dots,1)$ and $d_{2^L} = (0,\dots,0)$.

\begin{defn}
The randomized query $\map{A}{\Dsp^n}{\Ssp = \{0,\dots,n\}^{2^L}}$ maps collections of bit vectors to occurrence counts as follows.
\begin{enumerate}
\renewcommand{\labelenumi}{(\alph{enumi})}
\item Extend the bit randomization $R$ to collections $\xv$ by applying it independently to each vector:
\[ R(\xv) = R(\xv;\boldsymbol{\xi})
= \big(R(x_1;\xi_1),\dots,R(x_n; \xi_n)\big)
\quad\text{where } \xi_i = (\xi_{i1},\dots,\xi_{iL}) \text{ and }
\xi_{i\ell} \iid Ber(p). \]
We call $R(\xv)$ the \textbf{synthetic} collection obtained from the \textbf{original} collection $\xv$.
\item Define the function $\Phi$ that counts occurrences of the elements of $\Dsp = (d_1,\dots,d_{2^L})$ in a collection $\yv$:
\[ \Phi(\yv) := \left(\sum_{i = 1}^n I(y_i = d_1),\dots,
\sum_{i = 1}^n I(y_i = d_{2^L}).
\right)
\]
Note that, if $\Phi(\yv) = (s_1,\dots,s_{2^L})$, then $s_1 + \cdots + s_{2^L} = n$.
\end{enumerate}
Finally,
\[ A  = \Phi \circ R. \]
\end{defn}

The distribution of $A(\xv)$ is given by
\begin{align}
\P[A(\xv) = \sv] &= \P[\Phi(R(\xv)) = s]
= \sum_{\yv:\Phi(\yv) = s} \P[R(\xv) = \yv] \nonumber\\
&= \sum_{\yv:\Phi(\yv) = s} \prod_{i=1}^n \P[R(x_i) = y_i]
\label{eq:Adist}\\
&= \sum_{\yv:\Phi(\yv) = s} \prod_{i=1}^n p^{L - \delta(x_i,y_i)}\cdot
q^{\delta(x_i,y_i)}
= \sum_{\yv:\Phi(\yv) = s} p^{nL - \delta(\xv,\yv)}\cdot
q^{\delta(\xv,\yv)}  \nonumber
\end{align} 

\section{Maximal collections}

We will study the differential privacy of the query $A$ in terms of the \textbf{privacy ratio}
\[ \pi(\sv) := \frac{\P[A(\xv') = \sv]}{\P[A(\xv) = \sv]} \]
for two collections $\xv,\xv'\in\Dsp^n$ differing in one row and $\sv \in\Ssp$.
Note that $\pi$ is well-defined, since any outcome $\sv$ occurs with non-zero probability starting from any collection $\xv$.
By Proposition \ref{prop:dpcnt}, $A$ is $\epsilon$-differentially private if $\pi$ is bounded everywhere on $\Ssp$,
with $\epsilon = \max_{\sv\in\Ssp} \log\pi(\sv)$.

Without loss of generality (in light of \eqref{eq:Adist}), assume that the element differing between $\xv$ and $\xv'$ is the first one, and denote $\xvt = (x_2,\dots,x_n)$.
In other words, $\xv = (x_1,\xvt)$ and $\xv' = (x'_1, \xvt)$.
We also write $\iv_j = (0,\dots,0,1,0,\dots,0)$, the vector with a 1 in the $j$-th position and the rest 0.
%For convenience, introduce the notation
%$\sm_j = (s_1,\dots,s_{j-1},s_j - 1,s_{j+1},\dots,s_{2^L})$.

Conditioning on its value, we can write
\begin{equation} \label{eq:prcond}
\pi(s) = \frac{\displaystyle\sum_{j=1}^{2^L}
\P[A(x'_1) = \iv_j] \P[A(\xvt) = \sv - \iv_j]}
{\displaystyle\sum_{j=1}^{2^L}
\P[A(x_1) = \iv_j] \P[A(\xvt) = \sv - \iv_j]}
= \frac{\displaystyle\sum_{j=1}^{2^L}
\P[R(x'_1) = d_j] \P[A(\xvt) = \sv - \iv_j]}
{\displaystyle\sum_{j=1}^{2^L}
\P[R(x_1) = d_j] \P[A(\xvt) = \sv - \iv_j]}.
\end{equation}
TODO: consequences of this: \\
- difference between numerator and denominator is basically a reweighting of the same terms in the sum \\
- max value of ratio

The first question we address is for which pair of original and modified collections $\xv$ and $\xv'$ does $\pi$ obtain its maximum.

\subsection{The case $L = 1$}

It is instructive to first consider the case where each record in the collection consists of a single bit, as the expressions simplify considerably.
In this case, the outcome of $A$ essentially reduces to the number of 1s obtained in the synthetic collection $R(\xv)$.


\section{Old stuff}


%%% Independent randomization/RAPPOR form of DP

%% To prove in general (for sets other than measurable rectangles, represent
%% probability as an iterated integral over sections - only one will be different.

Furthermore, if $A$ randomizes each record in the database independently,
\ie $A(\boldsymbol{x}) = A(\boldsymbol{x}, \boldsymbol{X}) := 
\big(A_0(x_1, X_1),\dots,A_0(x_n,X_n)\big)$
where $X_i$ are independent,
then $\boldsymbol{S} = \boldsymbol{S}_0^n$ and $s = (s_1,\dots,s_n)$ with 
$s_i \in \boldsymbol{S}_0$. 
In this case
$P[A(\boldsymbol{x}) = s] = P[A_0(x_1) = s_1,\dots,A_0(x_n) = s_n]
= \prod P[A_0(x_i) = s_i]$.
If $\boldsymbol{x}$ and $\boldsymbol{x'}$ differ in one row (wlog $x_1 \neq x'_1$ and $x_i = x'_i$ for $i = 2,\dots,n$),
then
\[ \frac{P[A(\boldsymbol{x}) = s]}{P[A(\boldsymbol{x'}) = s]} = 
\frac{P[A_0(x_1) = s_1]}{P[A_0(x'_1) = s_1]}. \]
Therefore, in this case, the query $A$ will satisfy differential privacy if
\[ P[A_0(x) = s] \leq \epsilon \cdot P[A_0(x') = s] \]
for all $x,x' \in D$ and $s \in \boldsymbol{S}_0$.
This is the formulation used in the RAPPOR paper that applies to differences between individual records rather than collections differing on a single element.




\end{document}















